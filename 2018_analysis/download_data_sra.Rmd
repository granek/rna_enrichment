---
title: "Download Data"
output:
  html_document:
    toc: false
---

```{r}
source("run_config.R")

library(GEOquery)
library(dplyr)
library(rentrez)
library(readr)
library(stringr)
library(fs)
library(R.utils)
library(purrr)
library(tibble)
library(tools)
```

# Make Metadata Table with SRA and GEO Accesion Numbers
## Get SRA Metadata
This chunk doesn't need to be run because info is loaded from a file in the repo
```{r eval=FALSE, include=FALSE}
entrez_search(db="sra", term="PRJNA673133",retmax=1000) ->
  sra_search

# check that we got everything
stopifnot(sra_search[["count"]]==length(sra_search[["ids"]]))

entrez_fetch(db="sra", id=sra_search[["ids"]], rettype="runinfo") %>%
  read_csv %>%
  dplyr::select(Run, Experiment, SampleName) %>%
  filter(Run!="Run") ->
  sra_df
sra_df
```
## Get GEO Metadata
This chunk doesn't need to be run because info is loaded from a file in the repo
```{r eval=FALSE, include=FALSE}
getGEO("GSE160397",GSEMatrix=TRUE) ->
  gse
pData(gse[[1]]) %>%
  dplyr::select(geo_accession, sample_id=title, `enrichment method:ch1`, `genotype:ch1`, `media:ch1`, `rna sample number:ch1`) %>%
  rename_with(str_remove, .cols = everything(), ":ch1") %>%
  rename_with(str_replace_all, .cols = everything(), " ", "_") %>%
  filter(rna_sample_number %in% c("2", "3", "4")) %>%
  mutate(sequencing_batch=ifelse(str_detect(sample_id, "_2018_"),
                                "2019",
                                "2018")) %>%
  arrange(sequencing_batch, enrichment_method, rna_sample_number) ->
  geo_df
geo_df
```

## Join SRA and GEO Metadata
This chunk doesn't need to be run because info is loaded from a file in the repo
```{r eval=FALSE, include=FALSE}
right_join(sra_df, 
          geo_df, 
          by=c("SampleName"="geo_accession")) ->
  accessions_with_meta

accessions_with_meta %>%
  write_csv(accessions_file)
```
## Load Metadata From File
```{r}
accessions_file %>%
  read_csv ->
  accessions_with_meta
accessions_with_meta
```

# Download FASTQs from SRA
## fasterqDump Definition
```{r}
fasterqDump = function(accession,
                       outdir,
                       tempdir = NULL,
                       gzip = TRUE,
                       md5_df = NULL) {
  # Check if file is downloaded and OK
  accession %>%
    path_ext_set("fastq") ->
    fastq_file
  
  fastq_file %>%
    paste0(".gz") ->
    fastq_gz_file
  
  fastq_gz_file %>%
    file.path(outdir, .) ->
    fastq_gz_path
  
  fastq_file %>%
    file.path(outdir, .) ->
    fastq_path
  
  if (gzip == TRUE) {
    final_path = fastq_gz_path
  }
  else {
    final_path = fastq_path
  }
  
  if(!is.null(md5_df)){
    final_path %>%
      basename ->
      final_file
    
    final_path %>%
      md5sum ->
      observed_md5
    
    md5_df %>%
      filter(filename == final_file) %>%
      pull(md5sum) ->
      true_md5
    
    if (file.exists(final_path) && true_md5 == observed_md5){
      cat("MD5sum match", fastq_gz_path, true_md5, fill = TRUE)
      return(final_path)
    }
  }
  cat("Need to download", accession, fill = TRUE)
  fasterq_args =  c(accession, "--outdir", outdir)
  if (!is.null(tempdir)){
    # dir.create(tempdir, recursive = TRUE)
    fasterq_args =  c(fasterq_args, "--temp", tempdir)
  }
  system2(command="fasterq-dump",
          args=fasterq_args,
          stdout = TRUE,
          stderr = TRUE) ->
    std_err_out
  
  print(std_err_out)
  
  if (gzip == TRUE){
    if (file.exists(fastq_path)){
      final_path = gzip(fastq_path)
    } else {
      # check for paired reads
      r1_path = str_replace(fastq_path,".fastq", "_1.fastq")
      r2_path = str_replace(fastq_path,".fastq", "_2.fastq")
      final_path = c()
      if (file.exists(r1_path)){
        final_path = c(final_path, gzip(r1_path))
      }
      if (file.exists(r2_path)){
        final_path = c(final_path, gzip(r2_path))
      }
    }
  }
  return(final_path)
}
```

## Load "True" MD5sums from file
```{r}
srafastq_md5file %>%
  read_delim(delim=" ", 
             trim_ws = TRUE,
             col_names = c("md5sum", "filename")) ->
  srafastq_md5s
```

## Deal with vdb-config

# STOPPED HERE
  - https://standage.github.io/that-darn-cache-configuring-the-sra-toolkit.html
  - https://www.biostars.org/p/169617/
  - https://www.biostars.org/p/210819/
```{r}
stop("Deal with vdb-config")
```

```{bash}
cat  ~/.ncbi/user-settings.mkfg 
```

```{bash eval=FALSE, include=FALSE}
cp  ~/.ncbi/user-settings.mkfg   ~/.ncbi/user-settings.mkfg.BACKUP
chmod a-w ~/.ncbi/user-settings.mkfg.BACKUP
```


## Run Download (with cache check)
```{r}
accessions_with_meta %>%
  pull(Run) %>%
  map(function(x) fasterqDump(accession=x, outdir=sra_dir, tempdir="/workspace/tmp", md5_df=srafastq_md5s)) ->
  downloaded_fastqs
```


## Generate MD5 table
Only need to do this at the beginning
```{r eval=FALSE, include=FALSE}
downloaded_fastqs %>%
  unlist %>%
  md5sum %>%
  enframe %>%
  dplyr::rename(fullpath=name, md5sum=value) %>%
  mutate(filename=basename(fullpath)) %>%
  select(md5sum, filename) %>%
  write_delim(file.path(sra_dir, "md5_checksums.txt"), col_names = FALSE)
```

# SessionInfo
```{r}
sessionInfo()
```
